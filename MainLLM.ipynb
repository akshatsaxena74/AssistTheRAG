{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pranj\\anaconda3\\envs\\cuda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from huggingface_hub import HfApi\n",
    "import os\n",
    "from langchain.llms import HuggingFaceHub\n",
    "import re\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a helpful AI assistant who searches for the best answer to the given query:\n",
    "{question}\n",
    "\"\"\"\n",
    "# You may take help of the given context for replying:\n",
    "# {context}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline():\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  def predict(self, prompt):\n",
    "    llm = HuggingFaceHub(\n",
    "    repo_id=self.model,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 1.0,\n",
    "        # \"max_length\": self.max_length,\n",
    "        \"max_new_tokens\": 512,\n",
    "    }\n",
    "    )\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainLLM(pipeline):\n",
    "  def __init__(self, model, prompt_template):\n",
    "    super().__init__(model, )\n",
    "    self.prompt_template = prompt_template\n",
    "\n",
    "  def response(self, query):\n",
    "      formatted_query = self.prompt_template.format(question=query)\n",
    "      raw_answer = self.predict(formatted_query)\n",
    "      match = re.search(r\"(1\\..+)\\n(2\\..+)\", raw_answer, re.DOTALL)\n",
    "      if match:\n",
    "          query1 = match.group(1).strip()\n",
    "          query2 = match.group(2).strip()\n",
    "          return f\"{query}\\n{query1}\\n{query2}\"\n",
    "      else:\n",
    "          return raw_answer.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "query = \"Who won the football world cup 2024?\"\n",
    "temperature = 0.7\n",
    "max_new_tokens = 500\n",
    "max_length = 200\n",
    "\n",
    "assistant =  MainLLM(model, prompt_template)\n",
    "\n",
    "result = assistant.response(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI assistant who searches for the best answer to the given query:\n",
      "Who won the football world cup 2024?\n",
      "\n",
      "I'm sorry for any confusion, but as of the time of this response, the FIFA World Cup 2024 has not yet taken place. The next World Cup is scheduled for 2022 in Qatar, and the winner of that tournament has not been determined yet. I'll be happy to help you with more information about the upcoming World Cup or any other football-related topic!\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
